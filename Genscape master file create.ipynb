{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genscape API: Download all data to cvs and create xlsx pivot file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "APIKEY = 'INPUT HERE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenscapeApiHistory(url, ApiKey):\n",
    "\n",
    "    #Example ApiData = GenscapeApiHistory(\"https://api.genscape.com/transportation/oil/v1/pipeline-flows/weekly?startDate=2019-01-01\",\"abcde123456aa84848\")\n",
    "\n",
    "    import json\n",
    "    import http.client\n",
    "    import urllib.request\n",
    "    import urllib.parse\n",
    "    import urllib.error\n",
    "    import time\n",
    "\n",
    "    urlPieces = url.partition('?')\n",
    "    urlParameters = urlPieces[2]\n",
    "\n",
    "    if 'limit' in urlParameters or 'offset' in urlParameters or 'format' in urlParameters:\n",
    "\n",
    "        print(\"Please remove any offset, limit or format parameters from your API URL and try again\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        limit = 5000\n",
    "        offset = 0\n",
    "        i = 1\n",
    "        data = []\n",
    "        while True:\n",
    "\n",
    "            headers = {\n",
    "\n",
    "                'Gen-Api-Key': str(ApiKey),\n",
    "            }\n",
    "\n",
    "            params = urllib.parse.urlencode({\n",
    "                'limit': limit,\n",
    "                'offset': offset,\n",
    "                'format': 'json',\n",
    "            })\n",
    "\n",
    "            conn = http.client.HTTPSConnection('api.genscape.com')\n",
    "\n",
    "            conn.request(\"GET\", str(url)+\"&%s\" % params, \"{body}\", headers)\n",
    "            response = conn.getresponse()\n",
    "            decoded_data = response.read()\n",
    "            decoded_data2 = json.loads(decoded_data)\n",
    "            try:\n",
    "                decoded_data3 = decoded_data2['data']\n",
    "            except:\n",
    "                print(\n",
    "                    \"Empty Dataset: Please confirm your API URL and API Key are correct\")\n",
    "            data = data + decoded_data3\n",
    "            recvd = len(decoded_data3)\n",
    "            recvdTotal = len(data)\n",
    "            print(\"API call # \" + str(i) + \" returned \" + str(recvd) +\n",
    "                  \" rows for a total of \" + str(recvdTotal))\n",
    "            if recvd < limit:\n",
    "                break\n",
    "            offset += limit\n",
    "            i = i+1\n",
    "            time.sleep(2.1)\n",
    "        print(\"API returned a total of \" + str(len(data)) + \" rows\")\n",
    "\n",
    "        conn.close()\n",
    "\n",
    "        return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenscapeApi(url, ApiKey):\n",
    "\n",
    "    #Example ApiData = GenscapeApi(\"https://api.genscape.com/transportation/oil/v1/pipeline-flows/weekly?startDate=2019-01-01\",\"abcde123456aa84848\")\n",
    "\n",
    "    import json\n",
    "    import http.client\n",
    "    import urllib.request\n",
    "    import urllib.parse\n",
    "    import urllib.error\n",
    "\n",
    "    urlPieces = url.partition('?')\n",
    "    urlParameters = urlPieces[2]\n",
    "\n",
    "    if 'format' in urlParameters:\n",
    "\n",
    "        print(\"Please remove the format parameters from your API URL and try again\")\n",
    "\n",
    "    else:\n",
    "\n",
    "        data = []\n",
    "        while True:\n",
    "\n",
    "            headers = {\n",
    "                'Gen-Api-Key': str(ApiKey),\n",
    "            }\n",
    "\n",
    "            conn = http.client.HTTPSConnection('api.genscape.com')\n",
    "            conn.request(\"GET\", str(url), \"{body}\", headers)\n",
    "            response = conn.getresponse()\n",
    "            decoded_data = response.read()\n",
    "            decoded_data2 = json.loads(decoded_data)\n",
    "            try:\n",
    "                decoded_data3 = decoded_data2['data']\n",
    "            except:\n",
    "                print(\n",
    "                    \"Empty Dataset: Please confirm your API URL and API Key are correct\")\n",
    "            data = data + decoded_data3\n",
    "            recvd = len(decoded_data3)\n",
    "            print(\"API returned \" + str(recvd) + \" rows\")\n",
    "            break\n",
    "\n",
    "        conn.close()\n",
    "\n",
    "        return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_list():\n",
    "    df_url = pd.DataFrame({'name': ['df_pipe_mo_flow',\n",
    "                                    'df_pipe_day_flow',\n",
    "                                    'df_pipe_half_hourly',\n",
    "                                    'df_pipe_wk_netflow',\n",
    "                                    'df_pipe_day_netflow',\n",
    "                                    'df_rail_mo_flow',\n",
    "                                    'df_rail_day_flow',\n",
    "                                    'df_regs',\n",
    "                                    'df_meta',\n",
    "                                    'df_stor_reg',\n",
    "                                    'df_stor_own',\n",
    "                                    'df_stor_tank'\n",
    "                                    ],\n",
    "                           'url': ['https://api.genscape.com/transportation/oil/v2/pipeline-flows/monthly?revision=revised&startDate=2017-01-01',\n",
    "                                   'https://api.genscape.com/transportation/oil/v2/pipeline-flows/daily?revision=revised&startDate=2017-01-01',\n",
    "                                   'https://api.genscape.com/transportation/oil/v2/pipeline-flows/half-hourly?revision=revised&startDate=2017-01-01',\n",
    "                                   'https://api.genscape.com/transportation/oil/v1/pipeline-flows/net/cushing/weekly?revision=revised&startDate=2021-01-01',\n",
    "                                   'https://api.genscape.com/transportation/oil/v1/pipeline-flows/net/cushing/daily?revision=revised&startDate=2021-01-01',\n",
    "                                   'https://api.genscape.com/transportation/oil/v2/rail-flows/monthly?startDate=2017-01-01',\n",
    "                                   'https://api.genscape.com/transportation/oil/v2/rail-flows/daily?startDate=2017-01-01',\n",
    "                                   'https://api.genscape.com/transportation/oil/v1/pipeline-flows/regulatory?startDate=2017-01-01',\n",
    "                                   'https://api.genscape.com/transportation/oil/v1/pipelines',\n",
    "                                   'https://api.genscape.com/storage/oil/v1/region-volumes?revision=published&startDate=2017-01-01',\n",
    "                                   'https://api.genscape.com/storage/oil/v1/owner-volumes?revision=published&startDate=2017-01-01',\n",
    "                                   'https://api.genscape.com/storage/oil/v1/tank-volumes?revision=published&startDate=2017-01-01',\n",
    "\n",
    "                                   ]})\n",
    "    return df_url\n",
    "\n",
    "\n",
    "df_url = url_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url.to_csv('asdf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Half-hour data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call # 1 returned 5000 rows for a total of 5000\n",
      "API call # 2 returned 5000 rows for a total of 10000\n",
      "API call # 3 returned 3626 rows for a total of 13626\n",
      "API returned a total of 13626 rows\n"
     ]
    }
   ],
   "source": [
    "def pipe_halfhourly():\n",
    "    days_before = (datetime.date.today() -\n",
    "                   datetime.timedelta(days=2)).isoformat()\n",
    "    url = 'https://api.genscape.com/transportation/oil/v2/pipeline-flows/half-hourly?revision=revised&startDate=' + days_before\n",
    "    df = pd.DataFrame(GenscapeApiHistory(url, APIKEY))\n",
    "\n",
    "    date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "    df['reportDate'] = df['reportDate'].apply(\n",
    "        lambda x: datetime.datetime.strptime(x, date_format))\n",
    "\n",
    "    df['reportDate'] = df['reportDate'] + \\\n",
    "        pd.tseries.offsets.DateOffset(hours=-5)\n",
    "\n",
    "    df['year'] = df['reportDate'].dt.year\n",
    "    df['month'] = df['reportDate'].dt.month\n",
    "    df['day'] = df['reportDate'].dt.day\n",
    "    df['hour'] = 0\n",
    "    df['minute'] = 0\n",
    "    df['second'] = 0\n",
    "\n",
    "    df['date'] = pd.to_datetime(\n",
    "        df[['year', 'month', 'day', 'hour', 'minute', 'second']]).dt.date.astype('datetime64')\n",
    "\n",
    "    col = df.pop('date')\n",
    "    df.insert(0, col.name, col)\n",
    "    df = df.iloc[:, :-6]\n",
    "\n",
    "    df = df[df['date'] > min(df['date'])]\n",
    "    df1 = df\n",
    "    df1.to_csv('pipe_halfhourly.csv', index=False)\n",
    "    return df1\n",
    "\n",
    "\n",
    "df1 = pipe_halfhourly()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call # 1 returned 4590 rows for a total of 4590\n",
      "API returned a total of 4590 rows\n"
     ]
    }
   ],
   "source": [
    "def pipe_daily():\n",
    "    days_before = (datetime.date.today() -\n",
    "                   datetime.timedelta(days=45)).isoformat()\n",
    "    url = 'https://api.genscape.com/transportation/oil/v2/pipeline-flows/daily?revision=revised&startDate=' + days_before\n",
    "    df = pd.DataFrame(GenscapeApiHistory(url, APIKEY))\n",
    "\n",
    "    df['reportDate'] = pd.to_datetime(\n",
    "        df['reportDate']).dt.date.astype('datetime64')\n",
    "    df2 = df\n",
    "    df2.to_csv('pipe_daily.csv', index=False)\n",
    "    return days_before, df2\n",
    "\n",
    "\n",
    "days_before, df2 = pipe_daily()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Monthly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call # 1 returned 5000 rows for a total of 5000\n",
      "API call # 2 returned 1733 rows for a total of 6733\n",
      "API returned a total of 6733 rows\n"
     ]
    }
   ],
   "source": [
    "def pipe_monthly():\n",
    "    url = 'https://api.genscape.com/transportation/oil/v2/pipeline-flows/monthly?revision=revised&startDate=2017-01-01'\n",
    "    df = pd.DataFrame(GenscapeApiHistory(url, APIKEY))\n",
    "\n",
    "    df['reportDate'] = pd.to_datetime(\n",
    "        df['reportDate']).dt.date.astype('datetime64')\n",
    "    df3 = df\n",
    "    df3.to_csv('pipe_monthly.csv', index=False)\n",
    "    return df3\n",
    "\n",
    "\n",
    "df3 = pipe_monthly()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine half-hourly+daily data to create MTD pipe flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_hourly_todaily():\n",
    "    #df1 = pipe_halfhourly() #to get 3 days worth of data\n",
    "    #days_before, df2 = pipe_daily() #to get x 60 to 180 days worth of data\n",
    "    #df3 = pipe_monthly() #to get data since 1/1/17\n",
    "    df4 = pd.DataFrame()  # to add the halfhourly data to the daily data and create a new table\n",
    "\n",
    "    #get data to add to daily table\n",
    "    df = df1[df1['date'] > max(df2['reportDate'])]\n",
    "    df.drop('reportDate', axis=1, inplace=True)\n",
    "    df.rename(columns={'date': 'reportDate'}, inplace=True)\n",
    "    col_list_value = ['pipelineCapacity', 'flowBpd', 'confidenceId']\n",
    "    df = df.groupby(['reportDate', 'pipelineId', 'pipelineName', 'regionName', 'startPumpStation',\n",
    "                    'finishPumpStation', 'diameter', 'direction'])[col_list_value].mean()\n",
    "    df = df.reset_index()\n",
    "\n",
    "    df4 = df2.append(df, ignore_index=True)\n",
    "\n",
    "    df4.to_csv('pipe_daily&halfhourly.csv', index=False)\n",
    "    return df4\n",
    "\n",
    "\n",
    "df4 = pipe_hourly_todaily()\n",
    "\n",
    "\n",
    "def pipe_daily_add_to_master():\n",
    "    filename_path = 'df_pipe_daily_master.csv'\n",
    "    if not os.path.exists(filename_path):\n",
    "        print('### NEED TO CREATE DAILY MASTER FILE ###')\n",
    "        url = 'https://api.genscape.com/transportation/oil/v2/pipeline-flows/daily?revision=revised&startDate=2017-01-01'\n",
    "        df = pd.DataFrame(GenscapeApiHistory(url, APIKEY))\n",
    "        df.to_csv(filename_path, index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(filename_path)\n",
    "    df['reportDate'] = pd.to_datetime(\n",
    "        df['reportDate'], format=\"%Y-%m-%d\").astype('datetime64')\n",
    "\n",
    "    days_before_dt = datetime.datetime.fromisoformat(days_before)\n",
    "\n",
    "    df = df[df['reportDate'] < days_before_dt]\n",
    "\n",
    "    df = df.append(df4, ignore_index=True)\n",
    "    df5 = df\n",
    "    df5.to_csv(filename_path, index=False)\n",
    "    return df5\n",
    "\n",
    "\n",
    "df5 = pipe_daily_add_to_master()\n",
    "\n",
    "\n",
    "def pipe_monthly_add_to_master():\n",
    "    df = df5\n",
    "    df['year'] = df['reportDate'].dt.year\n",
    "    df['month'] = df['reportDate'].dt.month\n",
    "    df['day'] = 1\n",
    "    df['hour'] = 0\n",
    "    df['minute'] = 0\n",
    "    df['second'] = 0\n",
    "\n",
    "    df['date'] = pd.to_datetime(\n",
    "        df[['year', 'month', 'day', 'hour', 'minute', 'second']]).dt.date.astype('datetime64')\n",
    "\n",
    "    col = df.pop('date')\n",
    "    df.insert(0, col.name, col)\n",
    "    df = df.iloc[:, :-6]\n",
    "    df.drop('reportDate', axis=1, inplace=True)\n",
    "    df.rename(columns={'date': 'reportDate'}, inplace=True)\n",
    "    col_list_value = ['pipelineCapacity', 'flowBpd', 'confidenceId']\n",
    "    df = df.groupby(['reportDate', 'pipelineId', 'pipelineName', 'regionName', 'startPumpStation',\n",
    "                    'finishPumpStation', 'diameter', 'direction'])[col_list_value].mean()\n",
    "    df = df.reset_index()\n",
    "    df = df[df['reportDate'] > max(df3['reportDate'])]\n",
    "    df6 = df3.append(df, ignore_index=True)\n",
    "    df6.to_csv('df_pipe_monthly_master.csv', index=False)\n",
    "    return df6\n",
    "\n",
    "\n",
    "df6 = pipe_monthly_add_to_master()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cushing Netflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call # 1 returned 318 rows for a total of 318\n",
      "API returned a total of 318 rows\n",
      "API call # 1 returned 2229 rows for a total of 2229\n",
      "API returned a total of 2229 rows\n"
     ]
    }
   ],
   "source": [
    "def df_cushing_netflow():\n",
    "    url = 'https://api.genscape.com/transportation/oil/v1/pipeline-flows/net/cushing/weekly?revision=revised&startDate=2017-01-01'\n",
    "    df_weekly = pd.DataFrame(GenscapeApiHistory(url, APIKEY))\n",
    "    df_weekly.to_csv('df_cush_netflow_weekly.csv', index=False)\n",
    "    url = 'https://api.genscape.com/transportation/oil/v1/pipeline-flows/net/cushing/daily?revision=revised&startDate=2017-01-01'\n",
    "    df_daily = pd.DataFrame(GenscapeApiHistory(url, APIKEY))\n",
    "    df_daily.to_csv('df_cush_netflow_daily.csv', index=False)\n",
    "\n",
    "    return df_weekly, df_daily\n",
    "\n",
    "\n",
    "df_cushnet_weekly, df_cushnet_daily = df_cushing_netflow()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regulatory Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call # 1 returned 4251 rows for a total of 4251\n",
      "API returned a total of 4251 rows\n"
     ]
    }
   ],
   "source": [
    "def df_regulatory():\n",
    "    url = 'https://api.genscape.com/transportation/oil/v1/pipeline-flows/regulatory?startDate=2017-01-01'\n",
    "    df_reg = pd.DataFrame(GenscapeApiHistory(url, APIKEY))\n",
    "    df_reg['reportStartDate'] = pd.to_datetime(df_reg['reportStartDate'])\n",
    "\n",
    "    df_reg_qrt = df_reg\n",
    "    df_reg_qrt = df_reg_qrt[df_reg_qrt['frequency'] == 'Quarterly']\n",
    "    for i in range(2):\n",
    "        df_reg_qrt['reportStartDate'] = (df_reg_qrt['reportStartDate'].dt.floor(\n",
    "            'd') + pd.offsets.MonthEnd(2) - pd.offsets.MonthBegin(1))\n",
    "        df_reg = df_reg.append(df_reg_qrt)\n",
    "    df_reg.to_csv('df_regulatory.csv', index=False)\n",
    "    return df_reg\n",
    "\n",
    "\n",
    "df_reg = df_regulatory()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storage Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call # 1 returned 3816 rows for a total of 3816\n",
      "API returned a total of 3816 rows\n"
     ]
    }
   ],
   "source": [
    "def df_storage_region():\n",
    "    url = 'https://api.genscape.com/storage/oil/v1/region-volumes?revision=published&startDate=2017-01-01'\n",
    "    df_stor_reg = pd.DataFrame(GenscapeApiHistory(url, APIKEY))\n",
    "    df_stor_reg['reportDate'] = pd.to_datetime(df_stor_reg['reportDate'])\n",
    "    df_stor_reg.to_csv('df_Storage_Region.csv', index=False)\n",
    "    return df_stor_reg\n",
    "\n",
    "\n",
    "df_stor_reg = df_storage_region()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage by Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call # 1 returned 1128 rows for a total of 1128\n",
      "API returned a total of 1128 rows\n"
     ]
    }
   ],
   "source": [
    "def df_storage_owner():\n",
    "    filename_path = 'df_storage_owner_master.csv'\n",
    "    if not os.path.exists(filename_path):\n",
    "        print('### NEED TO CREATE DAILY MASTER FILE ###')\n",
    "        url = 'https://api.genscape.com/storage/oil/v1/owner-volumes?revision=published&startDate=2017-01-01'\n",
    "        df = pd.DataFrame(GenscapeApiHistory(url, APIKEY))\n",
    "        df.to_csv(filename_path, index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(filename_path)\n",
    "    df['reportDate'] = pd.to_datetime(\n",
    "        df['reportDate'], format=\"%Y-%m-%d\").astype('datetime64')\n",
    "    days_before_dt = datetime.datetime.fromisoformat(days_before)\n",
    "    df = df[df['reportDate'] < days_before_dt]\n",
    "\n",
    "    df.dtypes\n",
    "    df_stor_own = df\n",
    "\n",
    "    url = 'https://api.genscape.com/storage/oil/v1/owner-volumes?revision=published&startDate=' + days_before\n",
    "    df = pd.DataFrame(GenscapeApiHistory(url, APIKEY))\n",
    "    df['reportDate'] = pd.to_datetime(\n",
    "        df['reportDate'], format=\"%Y-%m-%d\").astype('datetime64')\n",
    "    df.to_csv('storage_owner.csv', index=False)\n",
    "    df.dtypes\n",
    "    #maxday_df = max(df['reportDate'])\n",
    "    #minday_df = min(df['reportDate'])\n",
    "\n",
    "    df_temp = df_stor_own.append(df, ignore_index=True)\n",
    "    df = df_temp\n",
    "    df['reportDate'] = pd.to_datetime(\n",
    "        df['reportDate'], format=\"%Y-%m-%d\").astype('datetime64')\n",
    "    df.dtypes\n",
    "    df.to_csv(filename_path, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_stor_own = df_storage_owner()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API returned 84 rows\n"
     ]
    }
   ],
   "source": [
    "def df_meta():\n",
    "    url = 'https://api.genscape.com/transportation/oil/v1/pipelines'\n",
    "    df_meta = pd.DataFrame(GenscapeApi(url, APIKEY))\n",
    "    df_meta['onlineDate'] = pd.to_datetime(\n",
    "        df_meta['onlineDate'], errors='coerce').dt.date\n",
    "    df_meta['effectiveDate'] = pd.to_datetime(\n",
    "        df_meta['effectiveDate'], errors='coerce').dt.date\n",
    "    df_meta.to_csv('df_PipelineMetadata.csv', index=False)\n",
    "    return df_meta\n",
    "\n",
    "\n",
    "df_meta = df_meta()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all data into a pivot to create xlsx file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlsx file with all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red River Cushing Outgoing Cushing Incoming\n",
      "Capline - Patoka to St. James Other Patoka Outgoing\n"
     ]
    }
   ],
   "source": [
    "def direction_reclass(x, y, z):\n",
    "    print(x, y, z)\n",
    "    df['flowBpd'] = np.where((df['pipelineName'] == x) & (\n",
    "        df['direction'] == y), df['flowBpd']*1, df['flowBpd']*-1)\n",
    "    df['confidenceId'] = np.where((df['pipelineName'] == x) & (\n",
    "        df['direction'] == y), df['confidenceId']*1, df['confidenceId']*-1)\n",
    "    df['pipelineCapacity'] = np.where((df['pipelineName'] == x) & (\n",
    "        df['direction'] == y), df['pipelineCapacity']*1, df['pipelineCapacity']*-1)\n",
    "\n",
    "    df['direction'] = np.where((df['pipelineName'] == x) & (\n",
    "        df['direction'] == y), z, df['direction'])\n",
    "    return df\n",
    "\n",
    "\n",
    "df = df6.copy()\n",
    "df = direction_reclass('Red River', 'Cushing Outgoing', 'Cushing Incoming')\n",
    "df = direction_reclass('Capline - Patoka to St. James',\n",
    "                       'Other', 'Patoka Outgoing')\n",
    "df10 = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENSCAPE_XLSX = 'genscape_data.xlsx'\n",
    "writer = pd.ExcelWriter(GENSCAPE_XLSX, engine='xlsxwriter')\n",
    "\n",
    "pivot_reg = df_reg.pivot_table(index=['regionName', 'pipelineName', 'source', 'frequency',\n",
    "                               'description'], columns=df_reg['reportStartDate'].dt.date, values='value').reset_index()\n",
    "pivot_reg.to_excel(writer, sheet_name='Reg', index=False)\n",
    "\n",
    "pivot_month_pipe_flow = df10.pivot_table(index=['regionName', 'pipelineName', 'direction', 'startPumpStation',\n",
    "                                         'finishPumpStation'], columns=df10['reportDate'].dt.date, values='flowBpd').reset_index()\n",
    "pivot_month_pipe_flow.to_excel(writer, sheet_name='Pipe_month', index=False)\n",
    "\n",
    "pivot_month_pipe_conf = df10.pivot_table(index=['regionName', 'pipelineName', 'direction', 'startPumpStation',\n",
    "                                         'finishPumpStation'], columns=df10['reportDate'].dt.date, values='confidenceId').reset_index()\n",
    "pivot_month_pipe_conf.to_excel(writer, sheet_name='Pipe_Conf', index=False)\n",
    "\n",
    "pivot_month_pipe_cap = df10.pivot_table(index=['regionName', 'pipelineName', 'direction', 'startPumpStation',\n",
    "                                        'finishPumpStation'], columns=df10['reportDate'].dt.date, values='pipelineCapacity').reset_index()\n",
    "pivot_month_pipe_cap.to_excel(writer, sheet_name='Pipe_Cap', index=False)\n",
    "\n",
    "pivot_daily_pipe_flow = df5.pivot_table(index=['regionName', 'pipelineName', 'direction', 'startPumpStation',\n",
    "                                        'finishPumpStation'], columns=df5['reportDate'].dt.date, values='flowBpd').reset_index()\n",
    "pivot_daily_pipe_flow.to_excel(writer, sheet_name='Pipe_Day', index=False)\n",
    "\n",
    "pivot_stor_reg = df_stor_reg.pivot_table(\n",
    "    index=['region', 'product'], columns=df_stor_reg['reportDate'].dt.date, values='storageAmount').reset_index()\n",
    "pivot_stor_reg.to_excel(writer, sheet_name='stor_reg', index=False)\n",
    "\n",
    "pivot_stor_reg_cap = df_stor_reg.pivot_table(\n",
    "    index=['region', 'product'], columns=df_stor_reg['reportDate'].dt.date, values='operationalCapacity').reset_index()\n",
    "pivot_stor_reg_cap.to_excel(writer, sheet_name='stor_reg_cap', index=False)\n",
    "\n",
    "pivot_stor_own = df_stor_own.pivot_table(index=['region', 'storageField', 'owner', 'product'],\n",
    "                                         columns=df_stor_own['reportDate'].dt.date, values='storageAmount').reset_index()\n",
    "pivot_stor_own.to_excel(writer, sheet_name='stor_own', index=False)\n",
    "\n",
    "pivot_stor_own_cap = df_stor_own.pivot_table(index=['region', 'storageField', 'owner', 'product'],\n",
    "                                             columns=df_stor_own['reportDate'].dt.date, values='operationalCapacity').reset_index()\n",
    "pivot_stor_own_cap.to_excel(writer, sheet_name='stor_own_cap', index=False)\n",
    "\n",
    "df_meta.to_excel(writer, sheet_name='Meta', index=False)\n",
    "\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xlsx file for model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/patdat/GSPE/main/Genscape%20Model%20List.csv'\n",
    "df_model_pipe = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pivot_pipe(x, y):\n",
    "    df = pd.merge(x, y, 'left', on=['pipelineName', 'direction'])\n",
    "#    df.reset_index( inplace=True)\n",
    "    df = df.drop(['regionName', 'startPumpStation',\n",
    "                 'finishPumpStation'], axis=1)\n",
    "    df = df.drop_duplicates(subset=['pipelineName', 'direction'], keep='last')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df_model_pipe_flow = model_pivot_pipe(df_model_pipe, pivot_month_pipe_flow)\n",
    "df_model_pipe_flow.iloc[:, 2:] = df_model_pipe_flow.iloc[:, 2:].div(\n",
    "    1000, axis=0)\n",
    "\n",
    "df_model_pipe_conf = model_pivot_pipe(df_model_pipe, pivot_month_pipe_conf)\n",
    "\n",
    "df_model_pipe_cap = model_pivot_pipe(df_model_pipe, pivot_month_pipe_cap)\n",
    "df_model_pipe_cap.iloc[:, 2:] = df_model_pipe_cap.iloc[:, 2:].div(1000, axis=0)\n",
    "\n",
    "\n",
    "GENSCAPE_XLSX = 'genscape_data_model.xlsx'\n",
    "writer = pd.ExcelWriter(GENSCAPE_XLSX, engine='xlsxwriter')\n",
    "\n",
    "df_model_pipe_flow.to_excel(writer, sheet_name='Pipe_Flow', index=False)\n",
    "df_model_pipe_conf.to_excel(writer, sheet_name='Pipe_Conf', index=False)\n",
    "df_model_pipe_cap.to_excel(writer, sheet_name='Pipe_Cap', index=False)\n",
    "\n",
    "writer.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd26ae16514ba5a2215df9416556d43934631b8bc10f68a1df061fb850337bfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
