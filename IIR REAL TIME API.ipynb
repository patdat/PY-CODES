{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api website: https://api.industrialinfo.com/\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "pd.set_option('display.max_columns', None)\n",
    "import os\n",
    "\n",
    "import json\n",
    "from io import StringIO\n",
    "import boto3\n",
    "\n",
    "codePath = os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''comment out code once token is generated'''\n",
    "\n",
    "token = 'INPUT THE TOKEN HERE THAT IS PRINTED'\n",
    "\n",
    "# def generate_token():\n",
    "#     params = {\n",
    "#         'username': 'INPUT USERNAME',\n",
    "#         'password': 'INPUT PASSWORD',\n",
    "#         'tokenLifeTime': '30',\n",
    "#     }\n",
    "#     response = requests.post('https://api.industrialinfo.com/idb/v2.0/token', params=params)\n",
    "#     token = response.headers['AUTHORIZATION'][7:]    \n",
    "#     return token, response\n",
    "# token,response = generate_token()\n",
    "# print(token)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call #1 returned 873 rows for a total of 873\n",
      "API returned a total of 873 rows\n"
     ]
    }
   ],
   "source": [
    "def get_data(eventStartDateMin,eventStartDateMax='2024-12-31'):\n",
    "    limit = 1000\n",
    "    offset = 0\n",
    "    i = 1\n",
    "    fd = pd.DataFrame()\n",
    "    while True:\n",
    "        headers = {\n",
    "            'Accept': 'application/json',\n",
    "            'Authorization': 'Bearer {}'.format(token),\n",
    "        }\n",
    "        params = {'eventStartDateMin': str(eventStartDateMin), 'eventStartDateMax': str(eventStartDateMax), 'limit': str(limit), 'offset': str(offset)}\n",
    "        response = requests.post('https://api.industrialinfo.com/idb/v2.0/offlineevents/summary', params=params, headers=headers)        \n",
    "        df = pd.DataFrame(response.json()['offlineEvents'])\n",
    "        fd = pd.concat([fd,df],axis=0)        \n",
    "        recvd = df.shape[0]\n",
    "        recvdTotal = fd.shape[0]\n",
    "        print('API call #' + str(i) + ' returned ' + str(recvd) + ' rows for a total of ' + str(recvdTotal))\n",
    "        if recvd < limit:\n",
    "            break\n",
    "        offset += limit\n",
    "        i = i+1        \n",
    "    print(\"API returned a total of \" + str(fd.shape[0]) + \" rows\")\n",
    "    \n",
    "    return fd\n",
    "df = get_data('2023-01-01','2023-02-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call #1 returned 360 rows for a total of 360\n",
      "API returned a total of 360 rows\n"
     ]
    }
   ],
   "source": [
    "def get_data(eventStartDateMin,eventStartDateMax='2024-12-31'):\n",
    "    limit = 1000\n",
    "    offset = 0\n",
    "    i = 1\n",
    "    fd = pd.DataFrame()\n",
    "    while True:\n",
    "        headers = {\n",
    "            'Accept': 'application/json',\n",
    "            'Authorization': 'Bearer {}'.format(token),\n",
    "        }\n",
    "        params = {'eventStartDateMin': str(eventStartDateMin), 'eventStartDateMax': str(eventStartDateMax), 'limit': str(limit), 'offset': str(offset),'derate' : 1}\n",
    "        response = requests.post('https://api.industrialinfo.com/idb/v2.0/offlineevents/summary', params=params, headers=headers)        \n",
    "        df = pd.DataFrame(response.json()['offlineEvents'])\n",
    "        fd = pd.concat([fd,df],axis=0)        \n",
    "        recvd = df.shape[0]\n",
    "        recvdTotal = fd.shape[0]\n",
    "        print('API call #' + str(i) + ' returned ' + str(recvd) + ' rows for a total of ' + str(recvdTotal))\n",
    "        if recvd < limit:\n",
    "            break\n",
    "        offset += limit\n",
    "        i = i+1        \n",
    "    print(\"API returned a total of \" + str(fd.shape[0]) + \" rows\")\n",
    "    \n",
    "    return fd\n",
    "df_derate = get_data('2023-01-01','2023-02-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df_derate.shape\n",
    "df.to_csv('asdf_noderate.csv')\n",
    "df_derate.to_csv('asdf_derate.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cleanData(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def normalizeJSON(self,raw):\n",
    "        '''the data has json in the columns so need to run this to normalize the data'''\n",
    "        df = raw.copy()        \n",
    "        df.set_index('offlineEventKey', inplace=True)\n",
    "        df.index.name = 'offlineEventKey'\n",
    "\n",
    "        lst = [\n",
    "            'plantPhysicalAddress',\n",
    "            'offlineCapacity',\n",
    "            'fuel',        \n",
    "            ]\n",
    "        for i in lst:\n",
    "            df_norm = pd.json_normalize(df[i])\n",
    "            df.drop([i], axis=1, inplace=True)\n",
    "            df_norm.index = df.index\n",
    "            df = pd.concat([df,df_norm], axis=1)\n",
    "        return df\n",
    "    \n",
    "    def convertDates(self,raw):\n",
    "        '''the data is a string so need to convert to datetime'''\n",
    "        df = raw.copy()\n",
    "        lst = [\n",
    "            'associatedEntityStartDate',\n",
    "            'associatedEntityEndDate',\n",
    "            'associatedEntityPrevStartDate',\n",
    "            'associatedEntityPrevEndDate',\n",
    "            'eventStartDate',\n",
    "            'eventEndDate',\n",
    "            'prevStartDate',\n",
    "            'prevEndDate',\n",
    "            'liveDate',\n",
    "            'releaseDate',\n",
    "            ]\n",
    "        for i in lst:\n",
    "            df[i] = df[i].str[:10] \n",
    "            df[i] = pd.to_datetime(df[i])\n",
    "        return df\n",
    "    \n",
    "    def dropUnecessaryColumns(self,raw):\n",
    "        '''these are columns mostly pointless for the exercise'''\n",
    "        df = raw.copy()\n",
    "        lst = [\n",
    "            'associatedEntityStartDate',\n",
    "            'associatedEntityEndDate',\n",
    "            'associatedEntityPrevStartDate',\n",
    "            'associatedEntityPrevEndDate',\n",
    "            'associatedEntityType',\n",
    "            'prevStartDate',\n",
    "            'prevEndDate',\n",
    "            'liveDate',\n",
    "            'isoRtoRegion',\n",
    "            'uom',\n",
    "            'releaseDate',\n",
    "            ]\n",
    "        df.drop(lst, axis=1, inplace=True)    \n",
    "        return df\n",
    "    \n",
    "    def renameTradeRegion(self,raw):\n",
    "        '''rename to preferred names'''\n",
    "        df = raw.copy()\n",
    "        regionAlt = {'I':'P1','II':'P2','III':'P3','IV':'P4','V':'P5'}\n",
    "        df['tradingRegionName'] = df['tradingRegionName'].replace(regionAlt)\n",
    "        countryAlt = {'U.S.A.':'USA'}\n",
    "        df['countryName'] = df['countryName'].replace(countryAlt)    \n",
    "        return df\n",
    "\n",
    "    def map_unitType(self):\n",
    "        df = pd.DataFrame.from_dict({\n",
    "            'Delayed Coker': 'COK',\n",
    "            'Hydrofluoric Alkylation': 'ALK',\n",
    "            'Semiregen/Cyclic Reformer': 'RFM',\n",
    "            'Distillate Hydrotreater': 'HT',\n",
    "            'Olefin/Aromatics Hydrotreater': 'HT',\n",
    "            'Diluent Recovery Unit (DRU)': 'DRU',\n",
    "            'Vacuum Distillation': 'VDU',\n",
    "            'Mid Distillate Hydrotreater': 'HT',\n",
    "            'Diesel Hydrotreater': 'HT',\n",
    "            'Distillate Hydrocracker': 'HCU',\n",
    "            'FCCU (Fluid Catalytic Cracker)': 'FCC',\n",
    "            'CCR(Continuous Catalytic Reformer)': 'RFM',\n",
    "            'HGO (Heavy Gas Oils) Hydrotreater': 'HT',\n",
    "            'Isomerization': 'ISO',\n",
    "            'LPG Liquid Petroleum Gas': 'LPG',\n",
    "            'Atmospheric Distillation': 'CDU',\n",
    "            'FCCU Gasoline Hydrotreater': 'HT',\n",
    "            'FCCU Feed Hydrotreater': 'HT',\n",
    "            'Reformer Feed Hydrotreater': 'HT',\n",
    "            'Visbreaker': 'VBU',\n",
    "            'Sulfuric Alkylation': 'ALK',\n",
    "            'Lube Oil Hydrotreater': 'HT',\n",
    "            'Residual Hydrocracker': 'HCU',\n",
    "            'Residual Hydrotreater': 'HT',\n",
    "            'Light Naphtha Hydrotreater': 'HT',\n",
    "            'RFCCU (Residue Fluid Catalytic Cracker)': 'FCC',\n",
    "            'Condensate Splitter': 'CDU',\n",
    "            'SR (Straight-Run) Hydrotreater': 'HT',\n",
    "            'Fluidized-Bed Coker': 'COK',\n",
    "            'Thermal Cracker': 'COK',\n",
    "            'TCCU Thermal Catalytic Cracking Unit': 'FCC',\n",
    "            'Hydrodealkylation': 'ALK',\n",
    "            'Lube Oil Hydrocracker': 'HCU',\n",
    "            },orient='index',columns=['unitType'])\n",
    "        df = df.reset_index()\n",
    "        df = df.rename(columns={'index':'unitTypeDesc'})\n",
    "        return df\n",
    "\n",
    "    def colUnitType(self,raw):\n",
    "        '''this is to create a custom column for unit type.  grabbing from local so need to change'''\n",
    "        df = raw.copy()\n",
    "        df.reset_index(inplace=True)\n",
    "        unitType = self.map_unitType()\n",
    "        df = df.merge(unitType, how='left', left_on='unitTypeDesc', right_on='unitTypeDesc')\n",
    "        df.set_index('offlineEventKey', inplace=True)\n",
    "        return df\n",
    "    \n",
    "    def runAll(self,raw):\n",
    "        '''this runs all the functions'''\n",
    "        df = self.normalizeJSON(raw)\n",
    "        df = self.convertDates(df)\n",
    "        df = self.dropUnecessaryColumns(df)\n",
    "        df = self.renameTradeRegion(df)\n",
    "        df = self.colUnitType(df)\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class processData(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def helperDateRange(self,beginning,ending):\n",
    "        start = pd.to_datetime(beginning, format='%Y-%m-%d')\n",
    "        end = pd.to_datetime(ending, format='%Y-%m-%d')\n",
    "        rng = pd.DataFrame({'BOM':pd.date_range(start=start, end=end, freq='M')+ pd.DateOffset(months=-1) + pd.tseries.offsets.MonthEnd(0),\n",
    "                            'EOM':pd.date_range(start=start, end=end, freq='M')})\n",
    "        rng['period'] = rng['EOM'].dt.strftime('%Y-%m')    \n",
    "        return rng\n",
    "\n",
    "    def selectFilters(self,raw,tradingRegionName=None,unitType=None,countryName=None):\n",
    "        df = raw.copy()\n",
    "        if tradingRegionName is not None:\n",
    "            df = df[df['tradingRegionName'] == tradingRegionName]\n",
    "        if unitType is not None:\n",
    "            df = df[df['unitType'] == unitType]\n",
    "        if countryName is not None:\n",
    "            df = df[df['countryName'] == countryName]\n",
    "            #eventstatusdesc does not equal cancelled\n",
    "        df = df[df['eventStatusDesc'] != 'Cancelled']               \n",
    "        return df\n",
    "\n",
    "    def minimizeData(self,raw):\n",
    "        df = raw.copy()\n",
    "        df = df[['eventStartDate','eventEndDate','unitCapacity','capacityOffline']]\n",
    "        return df\n",
    "\n",
    "    def calculateMonthly(self,raw,beginning,ending):\n",
    "        df = raw.copy()\n",
    "        df = df[df['eventEndDate'] >= beginning]\n",
    "        df = df[df['eventStartDate'] <= ending]\n",
    "\n",
    "        df['BOM'] = pd.to_datetime(beginning)\n",
    "        df['EOM'] = pd.to_datetime(ending)\n",
    "        df['MMM'] = df['EOM'].dt.strftime('%Y-%m')\n",
    "        \n",
    "        df['DAYS'] = (df[['eventEndDate','EOM']].min(axis=1) - df[['eventStartDate','BOM']].max(axis=1)).dt.days #this is to get the days in the month\n",
    "        df['DAYS'] = df['DAYS'].clip(lower=0) #this is to remove negative days\n",
    "        df['DAYS'] = np.where((df['eventStartDate'] + pd.tseries.offsets.MonthEnd(0)) == df['EOM'], df['DAYS'] + 1, df['DAYS']) #this is to add 1 day if the event end date is the last day of the month\n",
    "        df['DAYS'] = np.where(df['DAYS'] == 0,np.nan,df['DAYS']) #this is to remove 0 days\n",
    "        df.dropna(subset=['DAYS'], inplace=True)\n",
    "\n",
    "        df['DAYS_IN_MONTH'] = (df['EOM'] - df['BOM']).dt.days # this is to get the days in the month\n",
    "\n",
    "        df['CHARGE'] = round((df['DAYS'] / df['DAYS_IN_MONTH'] * df['capacityOffline'])/1000,2)\n",
    "        \n",
    "        df = df[['MMM','CHARGE']]        \n",
    "\n",
    "        return df\n",
    "\n",
    "    def runOneMonth(self,raw,beginning,ending,tradingRegionName=None,unitType='CDU',countryName='USA'):\n",
    "        df = self.selectFilters(raw,tradingRegionName,unitType,countryName)\n",
    "        df = self.minimizeData(df)\n",
    "        df = self.calculateMonthly(df,beginning,ending)\n",
    "        return df        \n",
    "\n",
    "    def runMultipleMonths(self,raw,beginning,ending,tradingRegionName=None,unitType='CDU',countryName='USA'):\n",
    "        rng = self.helperDateRange(beginning,ending)\n",
    "        fd = pd.DataFrame()\n",
    "        for i in range(len(rng)):\n",
    "            df = self.runOneMonth(raw,rng['BOM'][i],rng['EOM'][i],tradingRegionName,unitType,countryName)\n",
    "            fd = pd.concat([fd,df],axis=0)\n",
    "        return fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1521 = get_data('2015-01-01','2021-12-31')\n",
    "raw_1521 = cleanData().runAll(raw_1521)\n",
    "raw_1521.to_csv('IIR RAW 2015-2021.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API call #1 returned 1000 rows for a total of 1000\n",
      "API call #2 returned 1000 rows for a total of 2000\n",
      "API call #3 returned 1000 rows for a total of 3000\n",
      "API call #4 returned 1000 rows for a total of 4000\n",
      "API call #5 returned 1000 rows for a total of 5000\n",
      "API call #6 returned 1000 rows for a total of 6000\n",
      "API call #7 returned 1000 rows for a total of 7000\n",
      "API call #8 returned 1000 rows for a total of 8000\n",
      "API call #9 returned 1000 rows for a total of 9000\n",
      "API call #10 returned 1000 rows for a total of 10000\n",
      "API call #11 returned 1000 rows for a total of 11000\n",
      "API call #12 returned 1000 rows for a total of 12000\n",
      "API call #13 returned 1000 rows for a total of 13000\n",
      "API call #14 returned 1000 rows for a total of 14000\n",
      "API call #15 returned 1000 rows for a total of 15000\n",
      "API call #16 returned 4 rows for a total of 15004\n",
      "API returned a total of 15004 rows\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':  \n",
    "    \n",
    "    '''initial data download which is only downloaded once if it isn't in the directory'''\n",
    "    if not os.path.isfile('IIR RAW 2015-2021.csv'):\n",
    "        raw_1521 = get_data('2015-01-01','2021-12-31')\n",
    "        raw_1521 = cleanData().runAll(raw_1521)\n",
    "        raw_1521.to_csv('IIR RAW 2015-2021.csv')    \n",
    "\n",
    "    raw_1521 = pd.read_csv('IIR RAW 2015-2021.csv',index_col='offlineEventKey',parse_dates=['eventStartDate','eventEndDate'])\n",
    "    #convert productID to object\n",
    "    raw_1521['productId'] = raw_1521['productId'].astype('object')\n",
    "\n",
    "    '''refreshing data'''\n",
    "    raw = get_data('2022-01-01','2024-12-31')\n",
    "    raw = cleanData().runAll(raw)\n",
    "    raw.to_csv('IIR RAW 2022-2024.csv')\n",
    "    \n",
    "    '''combine historical 2015-2019 with the refreshed data'''\n",
    "    raw = pd.concat([raw_1521,raw],axis=0)\n",
    "    del raw_1521"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':  \n",
    "\n",
    "    df = processData().runMultipleMonths(raw,\n",
    "        '2017-12-31','2023-12-31',\n",
    "        tradingRegionName=None,unitType='CDU',countryName='USA')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd26ae16514ba5a2215df9416556d43934631b8bc10f68a1df061fb850337bfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
